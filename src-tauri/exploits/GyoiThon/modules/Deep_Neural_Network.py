from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelBinarizer
from typing import Tuple
import numpy as np
import codecs
import sys

x = []
y = []
in_file = "train_data/train_cms_in.txt"
best_parameters = {}

with codecs.open(in_file, 'r', 'utf-8') as fin:
        lines = fin.readlines()
        items = []

        for line in lines:
            words = line[:-2]
            train_words = words.split('@')
            items.append(train_words[2])
            x.append(train_words[4])
            y.append(train_words[1])
x_train = LabelBinarizer().fit_transform(x)
y_train = LabelBinarizer().fit_transform(y)

def x_fold_predict(kfold : KFold) -> Tuple[np.array]:
# Initialize the variables
    X = x_train
    y = y_train
    model= MLPClassifier(max_iter=10000)
    best_score = 0
    # Use for loop to travers each fold
    for train_ndx, test_ndx in kfold.split(X):
        train_x, train_y, test_x, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx] # split the train and validate set
        model.fit(train_x,train_y)
        # use the macro f1 score to measure models in each fold
        model_predicted = model.predict(test_x)
        score = accuracy_score(test_y, model_predicted)
        if score> best_score: # choose the best model
            best_score = score
            # use the best model to predict the test set
    return model
    
def grid_search():
    best_score = 0
    # traverse the parameter 1
    for solver in ['adam','lbfgs','sgd']:
        for hidden_layer_sizes in [10,20,30]: # traverse the parameter 2
        # define the training algorithm and other parameters
            clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,solver=solver,max_iter=10000)
            # define the metric to evaluate the model
            scores = cross_val_score(clf,x_train,y_train,cv=10)
            score = scores.mean() # get the average value
            if score > best_score:
                best_score = score
                # record the parameters with the best performance
                best_parameters = {'solver':solver,"hidden_layer_sizes":hidden_layer_sizes}
                # test the model performance on test set
    print('Best parameters:{}'.format(best_parameters))
    return best_parameters

if __name__ == "__main__":
    if sys.argv[1]=="-grid":
        grid_search()
    else:
        x_fold_predict(KFold(n_splits=int(sys.argv[1])))