import re
import requests
import sys
from bs4 import BeautifulSoup

def get_emails_and_ips(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    emails = set()
    ip_hosts = set()
    for a in soup.find_all("a", href=True):
        href = a["href"]
        if "mailto:" in href:
            email = re.findall(r"mailto:(\S+)", href)[0]
            emails.add(email)
        elif re.match(r"https?://(?:www\.)?(\S+)\.\S+", href):
            ip_host = re.findall(r"https?://(?:www\.)?(\S+)\.\S+", href)[0]
            ip_hosts.add(ip_host)
        elif re.match(r"(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})", href):
            ip_host = re.findall(r"(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})", href)[0]
            ip_hosts.add(ip_host)
    return emails, ip_hosts

def harvest_emails_and_ips(domain, output):
    url = f"https://www.google.com/search?q=site%3A{domain}&num=100"

    emails, ip_hosts = get_emails_and_ips(url)

    if len(emails) == 0 and len(ip_hosts) == 0:
        print("No emails or IP hosts found.")

    with open(output, "w") as f:
        for email in emails:
            f.write(email + "\n")
        for ip_host in ip_hosts:
            f.write(ip_host + "\n")

    print(f"Found {len(emails)} emails and {len(ip_hosts)} IP hosts. Saved to {output}")

if __name__ == '__main__':
    if len(sys.argv) != 5:
        print("Usage: python harvest.py -d <domain> -o <output>")
        sys.exit(1)

    if sys.argv[1] == '-d':
        domain = sys.argv[2]
    else:
        print("Invalid option: -d <domain>")
        sys.exit(1)

    if sys.argv[3] == '-o':
        output = sys.argv[4]
    else:
        output = "output.txt"

    harvest_emails_and_ips(domain, output)
